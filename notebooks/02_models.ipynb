{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Creation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1 - Fetching the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "X = np.load('/Users/lacottepaul/Desktop/weather-nowcasting/data/input_persistence.npy')\n",
    "Y = np.load('/Users/lacottepaul/Desktop/weather-nowcasting/data/target_persistence.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2 - Persistence model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can create the persistence model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = X.copy()  # as Y ranges from t=1 to t=49 and X from t=0 to t=48 we can just say we want Y_pred = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can now save the prediction to use it in our evalution notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/Users/lacottepaul/Desktop/weather-nowcasting/data/Y_pred.npy', Y_pred)\n",
    "np.save('/Users/lacottepaul/Desktop/weather-nowcasting/data/Y_true.npy', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.3 - Basic Unet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.4 - State of the art Unet  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try and use: **Shreya Agrawal, Luke Barrington, Carla Bromberg, John Burge, Cenk Gazen, Jason Hickey.** Machine Learning for Precipitation Nowcasting from Radar Images. https://doi.org/10.48550/arXiv.1912.12132 \n",
    "\n",
    "\n",
    "To implement the Unet available at: https://github.com/fabarca/google_unet_nowcast/blob/main/model_unet_nowcast.py to our data and see what we have compared to the more'basic' Unet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block(input_layer, n_channels):\n",
    "    residual = layers.Conv2D(n_channels, 1, padding=\"same\")(input_layer)  # short_skip\n",
    "\n",
    "    out_layer = layers.Conv2D(n_channels, 3, padding=\"same\")(input_layer)\n",
    "    out_layer = layers.BatchNormalization()(out_layer)\n",
    "    out_layer = layers.LeakyReLU(alpha=0.1)(out_layer)\n",
    "    out_layer = layers.Conv2D(n_channels, 3, padding=\"same\")(out_layer)\n",
    "\n",
    "    out_layer = layers.add([out_layer, residual])  # Add back residual\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "def down_block(input_layer, n_channels):\n",
    "    residual = layers.Conv2D(n_channels, 1, strides=2, padding=\"same\")(input_layer)  # short_skip\n",
    "\n",
    "    out_layer = layers.BatchNormalization()(input_layer)\n",
    "    out_layer = layers.LeakyReLU(alpha=0.1)(out_layer)\n",
    "    out_layer = layers.MaxPooling2D(2, strides=2, padding=\"same\")(out_layer)\n",
    "\n",
    "    out_layer = layers.BatchNormalization()(out_layer)\n",
    "    out_layer = layers.LeakyReLU(alpha=0.1)(out_layer)\n",
    "    out_layer = layers.Conv2D(n_channels, 3, padding=\"same\")(out_layer)\n",
    "\n",
    "    long_skip = out_layer\n",
    "    out_layer = layers.add([out_layer, residual])  # Add back residual\n",
    "\n",
    "    return out_layer, long_skip\n",
    "\n",
    "def up_block(input_layer, long_skip, n_channels):\n",
    "\n",
    "    out_layer = layers.concatenate([input_layer, long_skip], axis=-1)\n",
    "\n",
    "    residual = layers.Conv2DTranspose(n_channels, (2, 2), strides=(2, 2), padding='same')(out_layer)  # short_skip\n",
    "\n",
    "    out_layer = layers.UpSampling2D(2)(out_layer)\n",
    "    out_layer = layers.BatchNormalization()(out_layer)\n",
    "    out_layer = layers.LeakyReLU(alpha=0.1)(out_layer)\n",
    "    out_layer = layers.Conv2D(n_channels, 3, padding=\"same\")(out_layer)\n",
    "    out_layer = layers.BatchNormalization()(out_layer)\n",
    "    out_layer = layers.LeakyReLU(alpha=0.1)(out_layer)\n",
    "    out_layer = layers.Conv2D(n_channels, 3, padding=\"same\")(out_layer)\n",
    "\n",
    "    out_layer = layers.add([out_layer, residual])  # Add back residual\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "def get_model(height, width, channels, out_channels, is_classification=True):\n",
    "    inputs = layers.Input(shape=(height, width, channels))\n",
    "\n",
    "    basicx1 = basic_block(inputs, 32)\n",
    "\n",
    "    downx2, downx2_skip = down_block(basicx1, 32)\n",
    "    downx4, downx4_skip = down_block(downx2, 64)\n",
    "    downx8, downx8_skip = down_block(downx4, 128)\n",
    "    downx16, downx16_skip = down_block(downx8, 256)\n",
    "    downx32, downx32_skip = down_block(downx16, 512)\n",
    "    downx64, downx64_skip = down_block(downx32, 512)\n",
    "    downx128, downx128_skip = down_block(downx64, 1024)\n",
    "\n",
    "    centerx128 = basic_block(downx128, 1024)\n",
    "\n",
    "    upx64 = up_block(centerx128, downx128_skip, 1024)\n",
    "    upx32 = up_block(upx64, downx64_skip, 512)\n",
    "    upx16 = up_block(upx32, downx32_skip, 512)\n",
    "    upx8 = up_block(upx16, downx16_skip, 256)\n",
    "    upx4 = up_block(upx8, downx8_skip, 128)\n",
    "    upx2 = up_block(upx4, downx4_skip, 64)\n",
    "    upx1 = up_block(upx2, downx2_skip, 32)\n",
    "\n",
    "    if is_classification:\n",
    "        outputs = layers.Conv2D(out_channels, 3, activation=\"softmax\", padding=\"same\")(upx1)\n",
    "    else:\n",
    "        outputs = layers.Conv2D(out_channels, 3, activation=\"linear\", padding=\"same\")(upx1)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Build model example: \n",
    "#          6 radar images 256x256 -> predicts 4 classes of precipitation\n",
    "model = get_model(256, 256, 6, 4, is_classification=True)\n",
    "model.summary(line_length=120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
